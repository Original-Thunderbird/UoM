{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1ISRqlqinE9"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DUASDdTYinFD",
    "outputId": "e30aa35b-26ac-42f6-c069-026815a1fbde"
   },
   "outputs": [],
   "source": [
    "# load dictionary\n",
    "f = open('subjectivity_clues_hltemnlp05/subjclueslen1-HLTEMNLP05.tff', \"r\", encoding='utf-8')\n",
    "dictionary = {}\n",
    "raw = f.read().split('\\n')[:-1]\n",
    "for line in raw:\n",
    "    bar = line.split()\n",
    "    # print(bar)\n",
    "    word = bar[2][6:]\n",
    "    # key:word -> value:strength & polarity\n",
    "    if word not in dictionary:\n",
    "        if bar[0][5:] == 'weaksubj':\n",
    "            if bar[5][14:] == 'negative':\n",
    "                dictionary[word] = -5\n",
    "            elif bar[5][14:] == 'positive':\n",
    "                dictionary[word] = 5\n",
    "        if bar[0][5:] == 'strongsubj':\n",
    "            if bar[5][14:] == 'negative':\n",
    "                dictionary[word] = -10\n",
    "            elif bar[5][14:] == 'positive':\n",
    "                dictionary[word] = 10\n",
    "\n",
    "# evidence of whether a word is negated\n",
    "negation_set = ('no', 'not', \"hasn't\", \"haven't\", \"doesn't\", \"don't\", \"isn't\", \"wasn't\", \"weren't\", 'never', 'seldom', 'barely', 'rarely', \n",
    "                'hardly', 'overly', 'excessively')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXRQ2dRdinFH"
   },
   "outputs": [],
   "source": [
    "def read_data(source, collect, corpus, neg_switch):\n",
    "    f = open(source, \"r\", encoding='latin-1')\n",
    "    raw = f.read().split('\\n')[:-1]\n",
    "    num = len(raw)\n",
    "    if neg_switch == False:\n",
    "        for rev in raw:\n",
    "            words = word_tokenize(rev)\n",
    "            corpus.append(words)\n",
    "            for word in words:\n",
    "                if word not in collect:\n",
    "                    collect.append(word)\n",
    "    # words in negation_set will not be considered when forming feature vector.\n",
    "    # Instead, they are used to negate polarities later\n",
    "    else:\n",
    "        for rev in raw:\n",
    "            words = word_tokenize(rev)\n",
    "            corpus.append(words)\n",
    "            for word in words:\n",
    "                if word not in collect and word not in negation_set:\n",
    "                    collect.append(word)\n",
    "    return num # number of examples in current corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNLHhciAinFK"
   },
   "outputs": [],
   "source": [
    "# pol_switch == True: only consider words from MPQA\n",
    "# neg switch == True: consider if words are negated\n",
    "# occ_switch == True: word occurence instead of frequency is used to build feature vectors\n",
    "def body(pol_switch, neg_switch, occ_switch, dictionary):\n",
    "    # label of examples\n",
    "    label = []\n",
    "    # row vector of BOW\n",
    "    collect = []\n",
    "    # tokenized reviews\n",
    "    corpus = []\n",
    "    neg_num = read_data('corpus2/rt-polarity.neg', collect, corpus, neg_switch)\n",
    "    label.extend([-1 for i in range(neg_num)])\n",
    "    pos_num = read_data('corpus2/rt-polarity.pos', collect, corpus, neg_switch)\n",
    "    label.extend([1 for i in range(pos_num)])\n",
    "    \n",
    "    print(f'length of feature vector: {len(collect)}')\n",
    "    if pol_switch == True:\n",
    "        keys = list(dictionary.keys())\n",
    "        dollect = []\n",
    "        print(len(keys))\n",
    "        for word in collect:\n",
    "            if word in keys:\n",
    "                dollect.append(word)\n",
    "        print(f'# of words in MPQR: {len(dollect)}')\n",
    "\n",
    "    # gather feature vectors\n",
    "    rev_word_mat = [[0 for i in range(len(collect))] for j in range(len(corpus))]\n",
    "    if pol_switch == False and neg_switch == False and occ_switch == False:\n",
    "        for i in range(len(corpus)):\n",
    "            for word in corpus[i]:\n",
    "                if word in collect:\n",
    "                    rev_word_mat[i][collect.index(word)] += 1\n",
    "    if pol_switch == False and neg_switch == False and occ_switch == True:\n",
    "        for i in range(len(corpus)):\n",
    "            for word in corpus[i]:\n",
    "                if word in collect:\n",
    "                    rev_word_mat[i][collect.index(word)] = 1\n",
    "    elif pol_switch == True and neg_switch == False and occ_switch == True:\n",
    "        keys = list(dictionary.keys())\n",
    "        for i in range(len(corpus)):\n",
    "            for word in corpus[i]:\n",
    "                if word in collect:\n",
    "                    if word not in keys:\n",
    "                        rev_word_mat[i][collect.index(word)] = 1\n",
    "                    else: # words from MPQR, use weights in map\n",
    "                        rev_word_mat[i][collect.index(word)] = dictionary[word]\n",
    "    elif pol_switch == False and neg_switch == True and occ_switch == True:\n",
    "        for i in range(len(corpus)):\n",
    "            for j in range(len(corpus[i])):\n",
    "                if corpus[i][j] in collect:\n",
    "                    word = corpus[i][j]\n",
    "                    if j>0 and corpus[i][j-1] in negation_set: # current word is negated, so flip polarity \n",
    "                        rev_word_mat[i][collect.index(word)] = -1\n",
    "                    else:\n",
    "                        rev_word_mat[i][collect.index(word)] = 1\n",
    "    elif pol_switch == True and neg_switch == True and occ_switch == True:\n",
    "        keys = list(dictionary.keys())\n",
    "        for i in range(len(corpus)):\n",
    "            for j in range(len(corpus[i])):\n",
    "                if corpus[i][j] in collect:\n",
    "                    word = corpus[i][j]\n",
    "                    if j>0 and corpus[i][j-1] in negation_set: # current word is negated, so flip polarity\n",
    "                        if corpus[i][j] in keys: # words from MPQR, use weights in map\n",
    "                            rev_word_mat[i][collect.index(word)] = -dictionary[word]\n",
    "                        else:\n",
    "                            rev_word_mat[i][collect.index(word)] = -1\n",
    "                    else:\n",
    "                        if corpus[i][j] in keys: # words from MPQR, use weights in map\n",
    "                            rev_word_mat[i][collect.index(word)] = dictionary[word]\n",
    "                        else:\n",
    "                            rev_word_mat[i][collect.index(word)] = 1\n",
    "\n",
    "    mat_scaled = preprocessing.scale(rev_word_mat)\n",
    "    clf = LogisticRegression(random_state=0, max_iter=250)\n",
    "    scores = cross_val_score(clf, mat_scaled, label, cv=5)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zUBprOVwinFO",
    "outputId": "62d8e8e0-118e-4923-f621-918f4c50e494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature vector: 20304\n",
      "[0.73230192 0.74261603 0.73123827 0.73545966 0.72748593]\n"
     ]
    }
   ],
   "source": [
    "body(False, False, False, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "BcVNI-fCinFS",
    "outputId": "a2e469e0-e3ee-466a-d5b8-00c6ad4a7916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature vector: 20304\n",
      "[0.73323957 0.73933427 0.72795497 0.73733583 0.7260788 ]\n"
     ]
    }
   ],
   "source": [
    "body(False, False, True, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "CUatkya-inFV",
    "outputId": "0c81bcc1-772c-45e6-c197-36f9a6b4c237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature vector: 20295\n",
      "[0.72433193 0.74636662 0.72420263 0.73405253 0.73780488]\n"
     ]
    }
   ],
   "source": [
    "body(False, True, True, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "nHNPsYCeinFY",
    "outputId": "95e99ccc-ae67-498f-d612-d27787d283cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature vector: 20304\n",
      "6452\n",
      "# of words in MPQR: 3278\n",
      "[0.73323957 0.73933427 0.72795497 0.73733583 0.7260788 ]\n"
     ]
    }
   ],
   "source": [
    "body(True, False, True, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "E5BQi7F6inFb",
    "outputId": "38566a8a-b037-4a67-8d98-01dc9d5c50ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature vector: 20295\n",
      "6452\n",
      "# of words in MPQR: 3275\n",
      "[0.72433193 0.74636662 0.72420263 0.73405253 0.73780488]\n"
     ]
    }
   ],
   "source": [
    "body(True, True, True, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nU8tJmmfinFe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of examples: 10662\n",
      "# of negations in corpus: 1601; # of words in corpus: 230219; # of words in corpus from MPQR: 29632\n",
      "average sentence length: 21.59247795910711 average # of words from MPQR in each sentence: 2.7792159069592945\n"
     ]
    }
   ],
   "source": [
    "neg_count = 0\n",
    "word_count = 0\n",
    "MPQR_count = 0\n",
    "keys = list(dictionary.keys())\n",
    "corpus = []\n",
    "f = open('corpus2/rt-polarity.neg', \"r\", encoding='latin-1')\n",
    "raw = f.read().split('\\n')[:-1]\n",
    "corpus.extend(raw)\n",
    "f = open('corpus2/rt-polarity.pos', \"r\", encoding='latin-1')\n",
    "raw = f.read().split('\\n')[:-1]\n",
    "corpus.extend(raw)\n",
    "print(f'# of examples: {len(corpus)}')\n",
    "for rev in corpus:\n",
    "    words = word_tokenize(rev)\n",
    "    word_count += len(words)\n",
    "    for word in words:\n",
    "        if word in negation_set:\n",
    "            neg_count += 1\n",
    "        if word in keys:\n",
    "            MPQR_count += 1\n",
    "\n",
    "print(f'# of negations in corpus: {neg_count}; # of words in corpus: {word_count}; # of words in corpus from MPQR: {MPQR_count}')\n",
    "print(f'average sentence length: {word_count/len(corpus)} average # of words from MPQR in each sentence: {MPQR_count/len(corpus)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "review_classi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
