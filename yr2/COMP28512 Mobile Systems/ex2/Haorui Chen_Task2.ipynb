{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.1: Fourier series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "F = 500.0 ; \n",
    "Fs = 44100.0;   \n",
    "T = 1.0/Fs; \n",
    "y_a = [0]*500; y_b = [0]*500; y_c = [0]*500;\n",
    "#summing up sinusoids\n",
    "for n in range(0,500):\n",
    "    for m in range(0,500):\n",
    "        if m%2:\n",
    "            y_a[n] = y_a[n] + (1.0/m)*numpy.sin(2*numpy.pi*(m*F)*n*T); \n",
    "            y_b[n] = y_b[n] + (1.0/(m**2))*numpy.cos(2*numpy.pi*(m*F)*n*T); \n",
    "            if m==3:\n",
    "                y_c[n] = y_c[n] + (1.0/m)*numpy.sin(2*numpy.pi*(m*F)*n*T + numpy.pi/2);\n",
    "            else:\n",
    "                y_c[n] = y_c[n] + (1.0/m)*numpy.sin(2*numpy.pi*(m*F)*n*T); \n",
    "x = numpy.arange(0,500)*T\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.plot(x,y_a)   # plot y_a\n",
    "ax0.set_title(\"x(k)=Sum(k)((1/k)sin(2*pi*k*F*t)),k=1,3,5...\")\n",
    "ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"x(t)\")\n",
    "ax0.grid(True)\n",
    "fig, ax1 = pyplot.subplots(1)\n",
    "ax1.plot(x,y_b)   # plot y_b\n",
    "ax1.set_title(\"x(k)=Sum(k)((1/(k^2))cos(2*pi*k*F*t)),k=1,3,5...\")\n",
    "ax1.set_xlabel(\"Time/t\") ; ax1.set_ylabel(\"x(t)\")\n",
    "ax1.grid(True)\n",
    "fig, ax2 = pyplot.subplots(1)\n",
    "ax2.plot(x,y_c)   # plot y_c\n",
    "ax2.set_title(\"x(k)=Sum(k)((1/k)sin(2*pi*k*F*t)+Q),k=1,3,5...\")\n",
    "ax2.set_xlabel(\"Time/t\") ; ax2.set_ylabel(\"x(t)\")\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.1 Q&A:\n",
    "\n",
    "1. Comment on the waveforms obtained for about 4 or more non-zero harmonics.  \n",
    "    -Waveform of summation of sin waves looks basically like square waves, and that of cos waves looks like triangular waves. The third wavefrom has one of its counterparts shifted left by Π/2， thus the wave looks distorted.\n",
    "2. What would you expect the waveforms to look like if you could take a very large number of harmonics?  \n",
    "    -The first wave from will look like square wave, the second resembling triangular wave, the third will still be in strange shape.\n",
    "3. In what ways are waveforms (a) and (c) similar and different?   \n",
    "    -They are all summed up by sin waves, but (c) has a harmonic shifted left by Π/2 on k=3 than that of (a).\n",
    "4. In what ways are waveforms (a) and (b) related to each other?  \n",
    "    -They are of same amplitude and frequency.\n",
    "5. Why might waveforms (a) and (c) sound similar over an analog telephone line?  \n",
    "    -Because for telephone quality speech, ear is considered insensitive to phase, and their frequency components and amplitute of each component are all the same.\n",
    "6. If the waveform in (a) represented a sequence of pulses sent over an analog telephone line to represent a stream of bits, and the harmonics were affected by phase distortion to produce waveform (c), why might this cause a problem at the receiver?  \n",
    "    -Since sequence of pulses is sent by digital form, different values are represented by binary values. For wavefom like (a), '1' and '0' can be easily distinguished from each other and error is unlikely to occur when reading it, yet when phase distortion occured, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.2: Frequency-domain processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile \n",
    "import comp28512_utils as utils \n",
    "(sampling_freq, y) = wavfile.read(\"noisySinewave.wav\"); #original\n",
    "print \"original noisySinewave\"\n",
    "utils.Audio(y, rate=sampling_freq,)\n",
    "#print 0-500\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"original noisySinewave.wav\")\n",
    "ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"Voltage\")\n",
    "ax0.plot(y[0:500])\n",
    "ax0.grid(True)\n",
    "Y = numpy.array([0]*500)\n",
    "y_ext = numpy.array(y[0:500])\n",
    "#tb deleted\n",
    "y_ext_full = numpy.array(y)\n",
    "\n",
    "\n",
    "\n",
    "#FFT\n",
    "Y = numpy.fft.fft(y_ext)\n",
    "Y_amp = numpy.sqrt(numpy.power(Y.real,2)+numpy.power(Y.imag,2));\n",
    "#x with index    #only plot half!\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Amplitude graph of noisySinewave with frequency index\")\n",
    "ax0.set_xlabel(\"Frequency index k\") ; ax0.set_ylabel(\"Amplitude\")\n",
    "ax0.stem(Y_amp[0:250]/250)\n",
    "ax0.grid(True)\n",
    "x_Fs = numpy.arange(500)\n",
    "x_Fs = x_Fs*sampling_freq/500\n",
    "#x with Fs       #only plot half!\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Amplitude graph of noisySinewave with frequency\")\n",
    "ax0.set_xlabel(\"Frequency/Hz\") ; ax0.set_ylabel(\"Amplitude\")\n",
    "ax0.stem(x_Fs[0:250],Y_amp[0:250]/250)\n",
    "#plot real part\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Real part of noisySinewave, supposed to be symmetric\")\n",
    "ax0.set_xlabel(\"Frequency index k\") ; ax0.set_ylabel(\"Amplitude in real part\")\n",
    "ax0.stem(Y.real/250)\n",
    "ax0.grid(True)\n",
    "#plot imaginary part\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Imaginary part of noisySinewave, supposed to be anti-symmetric\")\n",
    "ax0.set_xlabel(\"Frequency index k\") ; ax0.set_ylabel(\"Amplitude in real part\")\n",
    "ax0.stem(Y.imag/250)\n",
    "ax0.grid(True)\n",
    "\n",
    "#filter\n",
    "for i in range(0,500):\n",
    "    if abs(Y_amp[i])<4000*250:\n",
    "        Y[i]=0+0j\n",
    "for i in range(1,250):\n",
    "    if(abs(Y[i])!=0):\n",
    "        print \"remaining freq sample: %dHz\"%(i*sampling_freq / 250)\n",
    "y_ifft = numpy.fft.ifft(Y)\n",
    "y_ifft = numpy.real(y_ifft)\n",
    "#use plot to check?\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"noisySinewave after noise elimination\")\n",
    "ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"Voltage\")\n",
    "ax0.plot(x_Fs,y_ifft)\n",
    "ax0.grid(True)\n",
    "\n",
    "Y_full = numpy.fft.fft(y_ext_full)\n",
    "Y_amp_full = numpy.sqrt(numpy.power(Y_full.real,2)+numpy.power(Y_full.imag,2));\n",
    "for i in range(0,3*sampling_freq):\n",
    "    if abs(Y_amp_full[i])<4000*len(y)/2:\n",
    "        Y_full[i]=0+0j\n",
    "y_ifft_full = numpy.fft.ifft(Y_full)\n",
    "y_ifft_full = numpy.real(y_ifft_full)\n",
    "y_ifft_full = numpy.int16(y_ifft_full)\n",
    "print \"noisySinewave after noise elimination\"\n",
    "utils.Audio(y_ifft_full, rate=sampling_freq,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.2 Q&A:\n",
    "\n",
    "1. If the original time-domain signal has N samples, how many frequency-domain samples do we obtain after performing the FFT?  Why do we only need to plot the first N/2 samples of the magnitude spectrum?  \n",
    "    -N samples. -Because according to Sampling Theorem, samples larger than N/2 represent frequency components that are filtered out.\n",
    "2. How is periodic part of the sound and the noise seen in the magnitude spectrum?  \n",
    "    -Frequency points for music have considerably higher amplitude and are disparsed; those for noise are lower in amplitude and distributed across range of frequency.\n",
    "3. How do you convert FFT frequency sample ('bin') number to frequency?  \n",
    "    -The lowest one is fundamental frequency which is Fs/N, frequency of each sample is its number times fundamental frequency, yet samples of frequencies larger than Fs/2 are symmetric with those below.\n",
    "4. Would you describe the noise as being 'white'?  Please explain your answer.  \n",
    "    -Yes, because the noise is composed by sound of almost all different frequencies from 0 to Fs(sampling frequency).\n",
    "5. What value of threshold was chosen and why?  \n",
    "    -Threshold value is 3000 as it is higher than highest amplitude of noise and lower than lowest amplitude of music.\n",
    "6. As you must apply the frequency-domain processing to the real and imaginary parts of the FFT individually, why would it be wrong to calculate thresholds for these parts individually rather than for the magnitude spectrum?  \n",
    "    -Because those parts themselves can't represent amplitude correctly\n",
    "7. After applying the inverse FFT, is the resulting processed signal real, i.e. does it have zero imaginary part?  If it were not real, what would you conclude from this?  \n",
    "    -Not real. Even though input of ifft is symmetric, imaginary part of ifft output still exist due to rounding error of CPU.\n",
    "8. Has any of the noise been removed by this ‘spectral subtraction’ process?  \n",
    "    -Yes.\n",
    "9. What Fourier series components are present in the periodic part of the sound?  \n",
    "    -That of 640Hz & 1280Hz.\n",
    "10. Did you have any chance of answering question 9 by just observing the time-domain waveform (i.e. if you had never heard of the FFT)?  \n",
    "    -No, because we cannot distinguish periodic part from original waveform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.3: Transforming music files to & from frequency-domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "x = numpy.arange(1024)\n",
    "Fs = 44100.0\n",
    "T = 1.0/Fs\n",
    "x = x * (1.0/Fs)\n",
    "y = [0]*1024\n",
    "for n in range(0,1024):\n",
    "    y[n] = numpy.sin( 2 * numpy.pi * 441 * n * T )\n",
    "y_ori = numpy.array(y)\n",
    "# plot original wave\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Original sine wave at F=441Hz\")\n",
    "ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"Voltage/v\")\n",
    "ax0.plot(x,y_ori)\n",
    "ax0.grid(True)\n",
    "# DCT\n",
    "Y = fftpack.dct(y_ori, norm='ortho')\n",
    "#plot magnitude\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Sine wave at F=441Hz in frequency domain\")\n",
    "ax0.set_xlabel(\"Freqency index\") ; ax0.set_ylabel(\"Amplitude\")\n",
    "ax0.stem(Y)\n",
    "ax0.grid(True)\n",
    "# iDCT\n",
    "y_rev = fftpack.idct(Y, norm='ortho')\n",
    "#plot retrieved wave\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Sine wave after idct at F=441Hz\")\n",
    "ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"Voltage/v\")\n",
    "ax0.plot(x,y_rev)\n",
    "ax0.grid(True)\n",
    "\n",
    "(Fs_msc, wy) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"before idct\"\n",
    "utils.Audio(wy, rate=Fs_msc,)\n",
    "j=0; wdctF=[]; ry=[]\n",
    "#dct process\n",
    "while j*1024<len(wy):\n",
    "    #truncate by length of 1024\n",
    "    if (j+1)*1024<=len(wy):\n",
    "        Y_trunc = wy[(j*1024):((j+1)*1024)]\n",
    "    else:\n",
    "        Y_trunc = wy[(j*1024):len(wy)]\n",
    "    dctF = fftpack.dct(Y_trunc, norm='ortho')    #dct\n",
    "    #record \n",
    "    wdctF.extend(dctF)\n",
    "    j+=1\n",
    "wdctF = numpy.array(wdctF)\n",
    "SM=max(abs(wdctF))         # Get maximum amplitude \n",
    "wdctF = wdctF/float(SM)    # Scale maximum to 1\n",
    "wdctF = numpy.array(wdctF * (2**15 - 0.5) -0.5) # expansion to 16-bit\n",
    "#save file\n",
    "f = open (\"freq.bin\",\"wb\")\n",
    "numpy.save(f,wdctF)\n",
    "f.close()\n",
    "#load file\n",
    "f = open (\"freq.bin\",\"rb\")\n",
    "rdctF = numpy.load(f)\n",
    "#idct process\n",
    "j=0\n",
    "while j*1024<len(rdctF):\n",
    "    #truncate by length of 1024\n",
    "    if (j+1)*1024<=len(rdctF):\n",
    "        Y_trunc = rdctF[(j*1024):((j+1)*1024)]\n",
    "    else:\n",
    "        Y_trunc = rdctF[(j*1024):(len(rdctF))]\n",
    "    idctT = fftpack.idct(Y_trunc, norm='ortho')    #dct\n",
    "    #print len(idctT)\n",
    "    #record \n",
    "    ry.extend(numpy.int16(idctT))\n",
    "    j+=1\n",
    "ry = numpy.array(ry)\n",
    "SM=max(abs(ry))         # Get maximum amplitude \n",
    "ry = ry/float(SM)    # Scale maximum to 1\n",
    "ry = numpy.int16(numpy.array(ry * (2**15 - 0.5) -0.5)) # expansion to 16-bit\n",
    "#play audio\n",
    "print \"after idct\"\n",
    "utils.Audio(ry, rate=Fs_msc,)\n",
    "#plot audio file after idct\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Audio file of frequency domain sample\")\n",
    "ax0.set_xlabel(\"Index\") ; ax0.set_ylabel(\"Amplitude\")\n",
    "ax0.plot(ry)\n",
    "ax0.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.3 Q&A:\n",
    "    \n",
    "1. Why does the music have to be split up into sections when we wish to to apply frequency domain processing?  \n",
    "    -Because they are not purely periodic, but if we split it into small segments then they'll all be short term periodic, thus can get DCT applied.\n",
    "2. Does the transformation, saving to a file, reading back from the file and/or reconstruction introduce any noticeable distortion?  \n",
    "    -No, because only minor changes on data will occur due to rounding error during transformation and reconstruction, save/load do not change data.\n",
    "3. If there was some distortion, what would be the cause of it?  \n",
    "    -The cause may be lose of precision due to rounding to int16. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.4: Principles of mp3 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sampling_freq, y) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"original HQ-music44100-mono.wav\"\n",
    "utils.Audio(y, rate=sampling_freq,)\n",
    "y_rev = [0]*len(y)\n",
    "for m in [3,4,5,6,8]: #NB\n",
    "    for n in [2,6,30,80]:\n",
    "        wdctF = []\n",
    "        j = 0\n",
    "        valve = 100*n\n",
    "        total_add = 0; total_pre = 0; total_fin = 0\n",
    "        while j*1024<len(y):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*1024<=len(y):\n",
    "                Y_trunc = y[(j*1024):((j+1)*1024)]\n",
    "            else:\n",
    "                Y_trunc = y[(j*1024):(len(y))]\n",
    "            Y = fftpack.dct(Y_trunc, norm='ortho')    #dct\n",
    "            #delete frequency samples that are too low to hear\n",
    "            Y[0]=0; Y[1]=0; Y[2]=0\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if sampling_freq*i/2.0/len(Y)>16000:\n",
    "                    Y[i] = 0\n",
    "                    total_pre += 1\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if abs(Y[i]) < valve: \n",
    "                    Y[i] = 0\n",
    "                    total_add +=1\n",
    "            total_fin += numpy.count_nonzero(Y)\n",
    "            #record \n",
    "            wdctF.extend(Y)\n",
    "            j+=1\n",
    "        #reduce NB\n",
    "        wdctF = numpy.array(wdctF)\n",
    "        SM=max(abs(wdctF))         # Get maximum amplitude \n",
    "        wdctF = wdctF/float(SM)    # Scale maximum to 1\n",
    "        wdctF = numpy.round(wdctF * (2**(2*m-1))) # expansion to NB=m\n",
    "        wdctF = numpy.round(wdctF * (2**(16-2*m))) #restore to original scale\n",
    "        j=0\n",
    "        while j*1024<len(wdctF):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*1024<=len(wdctF):\n",
    "                Y = wdctF[(j*1024):((j+1)*1024)]\n",
    "            else:\n",
    "                Y = wdctF[(j*1024):(len(wdctF))]\n",
    "            #count reamining nunbers\n",
    "            ybuff = fftpack.idct(Y, norm='ortho')\n",
    "            if (j+1)*1024<=len(y):\n",
    "                y_rev[(j*1024):((j+1)*1024)] = ybuff\n",
    "            else:\n",
    "                y_rev[(j*1024):len(y)] = ybuff\n",
    "            j+=1\n",
    "        print \"NB=%d, filter:A=%d, %d samples eventually, %d samples saved\\\n",
    "        \"%(2*m, valve, total_fin, total_add)\n",
    "        y_rev = numpy.array(y_rev)\n",
    "        #play y_rev\n",
    "        SM=max(abs(y_rev))         # Get maximum amplitude \n",
    "        y_rev = y_rev/float(SM)    # Scale maximum to 1\n",
    "        y_rev = numpy.round(y_rev * (2**15 - 1)) # expansion to NB=16\n",
    "        utils.Audio(numpy.int16(y_rev), rate=sampling_freq,)\n",
    "        #plot original discontinuity\n",
    "        if valve==600 and m==4:\n",
    "            fig, ax0 = pyplot.subplots(1)\n",
    "            ax0.set_title(\"Example of discontinuity after frequency domain pocessing, between 3rd and 4th frame\")\n",
    "            ax0.set_xlabel(\"Time/t\") ; ax0.set_ylabel(\"Voltage\")\n",
    "            ax0.plot(y_rev[3062:3082])\n",
    "            ax0.grid(True)\n",
    "print \"bit saving after reducing the bandwidth to 16 kHz is %.6d\"%(total_pre)\n",
    "fig, ax0 = pyplot.subplots(1)\n",
    "ax0.set_title(\"Frequency domain sample form \")\n",
    "ax0.set_xlabel(\"Index k\") ; ax0.set_ylabel(\"Voltage\")\n",
    "ax0.plot(wdctF)\n",
    "ax0.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.4 Q&A:\n",
    "    \n",
    "1. What saving in bit-rate can achieved by reducing the bandwidth to 16 kHz?  \n",
    "    -241172/802001 = 27.34%.   241172x16/20 = 192,938 bit/s\n",
    "2. What is the effect of varying the constant threshold?  What happens with a value that (a) is definitely too high, (b) too low and (c) potentially satisfactory?  Give the values.  \n",
    "    -As threshold become higher, sounds get more blurred since more samples have been filtered out, and clicks become clearer. When threshold=8000, clicks are rather noticable, audio starts to become distorted. When threshold=200, audio sounds basically like original one, yet bit-rate saving is hardly achieved. When threshold=600, audio still sounds like original one, and bit-rate saving is considerable, thus come to a balance.\n",
    "3. For the 'potentially satisfactory' threshold, what is the effect of quantising the remaining non-zero DCT coefficients to 8 bits per sample?  \n",
    "    -When NB=8, audio sounds like original version, yet clicking sound becomes noticable.\n",
    "4. For the 'potentially satisfactory' threshold, and 8 bits per DCT coefficient, assuming that you could send the zero-valued DCT coefficients at negligible cost, what bit-rate is required by this coding procedure?  What bit-rate saving (in percentage terms) is achieved?  \n",
    "    -bit-rate: 122202*8/20 = 48880 bit/s; bit-rate saving =  (882001×16-122202×8)/(882001×16)=93.07%. \n",
    "5. Did you observe any distortion in the form of 'clicks' due to discontinuities at frame boundaries?  \n",
    "    -Yes.\n",
    "6. If so, what causes these clicks?  Think carefully about this and consider why you do not get clicks until you start doing some frequency domain processing.  \n",
    "    -Discintunities between last sample of former frame and first sample of latter frame. Because we are changing values of frequency domain samples, when we convert these frames back to time domain, continuity between frames will be broken and clicks appear ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2.5: Simple method for eliminating discontinuities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "print len(y)\n",
    "x_ind = range(3062,3082)\n",
    "y_rev = [0]*len(y)\n",
    "for n in range(1,6):\n",
    "        wdctF = []\n",
    "        j=0; z=0\n",
    "        valve = 600\n",
    "        while j*1024<len(y):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*1024<=len(y):\n",
    "                Y_trunc = y[(j*1024):((j+1)*1024)]\n",
    "            else:\n",
    "                Y_trunc = y[(j*1024):(len(y))]\n",
    "            Y = fftpack.dct(Y_trunc, norm='ortho')    #dct\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if sampling_freq*i/2.0/len(Y)>16000: \n",
    "                    Y[i] = 0\n",
    "            total_pre += numpy.count_nonzero(Y)\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if abs(Y[i]) < valve: \n",
    "                    Y[i] = 0\n",
    "            #record \n",
    "            wdctF.extend(Y)\n",
    "            j+=1\n",
    "        #reduce NB\n",
    "        wdctF = numpy.array(wdctF)\n",
    "        SM=max(abs(wdctF))         # Get maximum amplitude \n",
    "        wdctF = wdctF/float(SM)    # Scale maximum to 1\n",
    "        wdctF = numpy.round(wdctF * (2**(8-1) - 1)) # expansion to NB=8\n",
    "        wdctF = numpy.round(wdctF * (2**(16-8) - 1)) #restore to original scale\n",
    "        j=0\n",
    "        while j*1024<len(wdctF):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*1024<=len(wdctF):\n",
    "                Y = wdctF[(j*1024):((j+1)*1024)]\n",
    "            else:\n",
    "                Y = wdctF[(j*1024):(len(wdctF))]\n",
    "            ybuff = fftpack.idct(Y, norm='ortho')\n",
    "            if j>0:  #smoothing by z from last frame\n",
    "                for k in range(0,2*n):\n",
    "                    ybuff[k] = (math.e**k*ybuff[k]+z)/(math.e**k+1)\n",
    "            z = ybuff[len(ybuff)-1] #update z for next frame\n",
    "            if (j+1)*1024<=len(y):\n",
    "                y_rev[(j*1024):((j+1)*1024)] = ybuff\n",
    "            else:\n",
    "                y_rev[(j*1024):len(y)] = ybuff\n",
    "            j+=1\n",
    "        print \"use first %d samples for smoothing by z from last frame\"%(2*n)\n",
    "        y_rev = numpy.array(y_rev)\n",
    "        SM=max(abs(y_rev))         # Get maximum amplitude \n",
    "        y_rev = y_rev/float(SM)    # Scale maximum to 1\n",
    "        y_rev = numpy.round(y_rev * (2**15 - 1)) # expansion to NB=16\n",
    "        utils.Audio(numpy.int16(y_rev), rate=sampling_freq,)\n",
    "        fig, ax0 = pyplot.subplots(1)\n",
    "        ax0.set_title(\"Smoothing effect of the same part as 2.4 using %d samples\"%(2*n))\n",
    "        ax0.set_xlabel(\"Index k\") ; ax0.set_ylabel(\"Voltage\")\n",
    "        ax0.plot(x_ind,y_rev[3062:3082])\n",
    "        ax0.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.5 Q&A:\n",
    "    \n",
    "1. Describe the principle of your simple method and how it was implemented.  \n",
    "    -For each frame I store the last sample, and for first several samples, say x[k], I apply x[k] = (e^k×x[k]+z)/(e^k+1), giving z higher weight in altered sample to get them as close value of z as possible. \n",
    "2. Does it work?  If so how well does it work?  \n",
    "    -It works, though clicks are still noticable, they become slighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.6: Run-length & Huffman coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wdctF = []\n",
    "y_rev = [0]*len(y)\n",
    "j=0; z=0\n",
    "valve = 600\n",
    "all_count=0; sam_count=0\n",
    "while j*1024<len(y):\n",
    "    #truncate by length of 1024\n",
    "    if (j+1)*1024<=len(y):\n",
    "        Y_trunc = y[(j*1024):((j+1)*1024)]\n",
    "    else:\n",
    "        Y_trunc = y[(j*1024):(len(y))]\n",
    "    Y = fftpack.dct(Y_trunc, norm='ortho')    #dct\n",
    "    Y[0]=0; Y[1]=0; Y[2]=0\n",
    "    if j==0:\n",
    "        sam_count += 3\n",
    "    all_count+=3\n",
    "    #apply valve\n",
    "    for i in range(0,len(Y)):\n",
    "        if abs(Y[i]) < valve or sampling_freq*i/2.0/len(Y)>16000: \n",
    "            Y[i] = 0  \n",
    "        else:\n",
    "            if j==0:\n",
    "                sam_count += 1\n",
    "            all_count+=1\n",
    "    count = 0; flag = 0\n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i]==0 and (i==0 or Y[i-1] != 0):\n",
    "            count=1\n",
    "        elif Y[i]==0 and Y[i-1] == 0:\n",
    "            count+=1\n",
    "            if (count+1) // 257:\n",
    "                all_count += 1\n",
    "                count = 0\n",
    "                if j==0:\n",
    "                    sam_count += 1\n",
    "        elif Y[i]!=0:\n",
    "            count = 0\n",
    "    #record \n",
    "    wdctF.extend(Y)\n",
    "    j+=1\n",
    "#reduce NB\n",
    "wdctF = numpy.array(wdctF)\n",
    "SM=max(abs(wdctF))         # Get maximum amplitude \n",
    "wdctF = wdctF/float(SM)    # Scale maximum to 1\n",
    "wdctF = numpy.round(wdctF * (2**(8-1) - 1)) # expansion to NB=8\n",
    "wdctF = numpy.round(wdctF * (2**(16-8) - 1)) #restore to original scale\n",
    "j=0\n",
    "while j*1024<len(rdctF):\n",
    "    #truncate by length of 1024\n",
    "    if (j+1)*1024<=len(rdctF):\n",
    "        Y = wdctF[(j*1024):((j+1)*1024)]\n",
    "    else:\n",
    "        Y = wdctF[(j*1024):(len(wdctF))]\n",
    "    \n",
    "    ybuff = fftpack.idct(Y, norm='ortho')\n",
    "    if (j+1)*1024<=len(y):\n",
    "        y_rev[(j*1024):((j+1)*1024)] = ybuff\n",
    "    else:\n",
    "        y_rev[(j*1024):len(y)] = ybuff\n",
    "    j+=1\n",
    "#print all_count\n",
    "sam_save = (1024*8-sam_count*16) / 0.023\n",
    "sam_save_per = sam_save*0.023/(1024*8)\n",
    "all_save = (len(y)*8-all_count*16) /20.0\n",
    "all_save_per = all_save*20.0/(len(y)*8)\n",
    "print \"bit-saving for a typical frame is %d, %.6s, for whole file is %d, %.6s\\\n",
    "\"%(sam_save, sam_save_per, all_save,all_save_per )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.6 Q&A:\n",
    "\n",
    "1. What bit-rate saving was achieved for the single frame by run-length coding of zeros?   \n",
    "    -It's 252521, percentage is 70.89%.\n",
    "2. What bit-rate saving was achieved for the whole file by run-length coding of zeros?  \n",
    "    -It's 207985, percentage is 58.95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.7: Eliminating discontinuities using overlapping frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in [7,8,10,12]: #NB\n",
    "    for n in [0.8,8,9,30,80]:\n",
    "        j = 0\n",
    "        wdctF = []\n",
    "        valve = 100*n\n",
    "        total_fin = 0; total_pre = 0\n",
    "        while j*1024<len(y):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*1024<=len(y):\n",
    "                Y_trunc = y[(j*1024):((j+2)*1024)]\n",
    "            else:\n",
    "                Y_trunc = y[(j*1024):(len(y))]\n",
    "            Y_trunc = Y_trunc * numpy.hanning(len(Y_trunc)) #apply hamming window\n",
    "            Y = fftpack.dct(Y_trunc, norm='ortho')    #dct\n",
    "            #delete frequency samples that are too low to hear\n",
    "            Y[0]=0; Y[1]=0; Y[2]=0\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if sampling_freq*i/2.0/len(Y)>16000: \n",
    "                    Y[i] = 0\n",
    "            total_pre += numpy.count_nonzero(Y)\n",
    "            #apply valve\n",
    "            for i in range(0,len(Y)):\n",
    "                if abs(Y[i]) < valve: \n",
    "                    Y[i] = 0\n",
    "            #record\n",
    "            wdctF.extend(Y)\n",
    "            j+=1\n",
    "        #reduce NB\n",
    "        wdctF = numpy.array(wdctF)\n",
    "        SM=max(abs(wdctF))         # Get maximum amplitude \n",
    "        wdctF = wdctF/float(SM)    # Scale maximum to 1\n",
    "        wdctF = numpy.round(wdctF * (2**m - 1)) # expansion to NB=m\n",
    "        wdctF = numpy.round(wdctF * (2**(16-m) - 1)) #restore to original scale\n",
    "        y_res=numpy.array([])\n",
    "        y_pre = numpy.array([0]*1024)\n",
    "        j=0\n",
    "        while j*2048<len(wdctF):\n",
    "            #truncate by length of 1024\n",
    "            if (j+1)*2048<=len(wdctF):\n",
    "                Y = wdctF[(j*2048):((j+1)*2048)]\n",
    "            else:\n",
    "                Y = wdctF[(j*2048):(len(wdctF))]\n",
    "            #count reamining numbers\n",
    "            total_fin += numpy.count_nonzero(Y)\n",
    "            y_rev = fftpack.idct(Y, norm='ortho')   #iDCT\n",
    "            #split idct res into 2 parts, \n",
    "            #sum the first half of the current received frame with the second half of the previous received frame\n",
    "            y_rev_pre = numpy.array(y_rev[0:1024]); y_rev_aft = numpy.array(y_rev[1024:len(y_rev)])\n",
    "            y_res = numpy.append(y_res, y_pre+y_rev_pre) #save to final res\n",
    "            y_pre = y_rev_aft #prepare for adding of next frame\n",
    "            j+=1\n",
    "        #the final last half do not need to add up with other frames, yet it need to be appended to final result\n",
    "        print \"NB=%d, A=%d, remain %d samples, sample per frame: %s\\\n",
    "        \"%(m, valve, total_fin, total_fin*1.0/(j-1))\n",
    "        y_res = numpy.append(y_res, y_pre)\n",
    "        SM=max(abs(y_res))         # Get maximum amplitude \n",
    "        y_res = y_res/float(SM)    # Scale maximum to 1\n",
    "        y_res = numpy.round(y_res * (2**15 - 1)) # expansion to NB=m\n",
    "        wavfile.write(\"NB=%d_A=%d\"%(m, valve), sampling_freq, numpy.int16(y_res));\n",
    "        utils.audio_from_file(\"NB=%d_A=%d\"%(m, valve))  # play rendered speech from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 2.7 Q&A:\n",
    "\n",
    "1. With the best threshold for constant masking, how many non-zero DCT coefficients are there per frame on average?  \n",
    "    -A=800, there are 257.07 samples on average.\n",
    "2. How many bits per DCT coefficient did you find are really needed?  \n",
    "    -8 bits.\n",
    "3. If we could find a way of sending the zero valued DCT coefficients at no cost (or very little cost), estimate the bit-rate saving that would result from the three techniques considered above.  \n",
    "    -bit-rate saving: (1764002×16-220182×8)/20 = 1323128 bit/s   \n",
    "    -percentage: (1764002×16-220182×8)/(1764002×16)=93.76%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
